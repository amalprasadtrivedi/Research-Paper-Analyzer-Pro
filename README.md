
# ğŸ§  Research Paper Analyzer Pro

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/python-3.10+-blue.svg)
![Streamlit](https://img.shields.io/badge/streamlit-%23FF4B4B.svg?style=for-the-badge&logo=streamlit&logoColor=white)

## ğŸ“š Overview

**Research Paper Analyzer Pro** is an advanced Machine Learning and AI-powered application designed to assist researchers, students, and academicians in analyzing research papers with high accuracy. It provides domain classification, keyword extraction, summary generation, plagiarism detection, and more â€” all in a user-friendly web application powered by **Streamlit**.

---

## âœ¨ Features

- ğŸ” **Domain Classification** â€” Identifies the field of research (e.g., AI, Physics, Biology)
- ğŸ“Œ **Keyword Extraction** â€” Extracts important keywords from the paper
- ğŸ“ **Summary Generation** â€” Summarizes the research paper using NLP techniques
- âš ï¸ **Plagiarism Detection** â€” Compares paper against a database to check for similarity
- ğŸ“¥ **PDF Upload & Viewer** â€” Upload your paper and view it inside the app
- ğŸ“Š **Explainable AI** â€” Understand AI decisions with transparency

---

## ğŸš€ Demo

> Streamlit app interface showing PDF preview, NLP-based insights, and visual components.

*(Include screenshots here)*

---

## ğŸ“ Project Structure

```
Research-Paper-Analyzer-Pro/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                   # Streamlit App
â”‚   â””â”€â”€ config.py                 # App configurations
â”‚
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ models/                   # Trained ML models and embeddings
â”‚       â”œâ”€â”€ domain_classifier.pkl
â”‚       â””â”€â”€ vectorizer.pkl
â”‚
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ domain_classifier.py      # Domain classification logic
â”‚   â”œâ”€â”€ plagiarism_checker.py     # Semantic plagiarism detection
â”‚   â”œâ”€â”€ summarizer.py             # Paper summarization
â”‚   â”œâ”€â”€ keyword_extractor.py      # RAKE keyword extraction
â”‚   â””â”€â”€ utils.py                  # Utility functions
â”‚
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ train_domain_classifier.py
â”‚   â””â”€â”€ build_embeddings.py
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ğŸ› ï¸ Installation

### âœ… Requirements

- Python >= 3.10
- pip

### ğŸ Create a Virtual Environment (optional but recommended)

```bash
python -m venv venv
source venv/bin/activate   # On Windows: venv\Scripts\activate
```

### ğŸ“¦ Install Dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸ“¤ How to Run

```bash
streamlit run app/main.py
```

After running, the app will open in your browser.

---

## ğŸ” Module Descriptions

### 1ï¸âƒ£ Domain Classifier

- Uses **TF-IDF + Logistic Regression**
- Trained on abstracts from diverse research fields
- Predicts the domain: AI, Physics, Biology, etc.

```python
# Usage
from modules.domain_classifier import classify_paper
result = classify_paper("Your research paper abstract here")
```

### 2ï¸âƒ£ Keyword Extractor

- Implements **RAKE (Rapid Automatic Keyword Extraction)**
- Extracts key phrases to give semantic overview

### 3ï¸âƒ£ Summarizer

- Uses **HuggingFace Transformers**
- Models like `distilbart-cnn-12-6` to summarize paragraphs

### 4ï¸âƒ£ Plagiarism Checker

- Uses **SBERT** for sentence embeddings
- Calculates **cosine similarity**
- Matches input against existing paper embeddings

```python
from modules.plagiarism_checker import check_plagiarism
matches = check_plagiarism("research content")
```

---

## ğŸ§ª Example Usage

```python
# Example to classify paper
from modules.domain_classifier import classify_paper
result = classify_paper("Deep Learning in Military Applications")

# Example to check plagiarism
from modules.plagiarism_checker import check_plagiarism
matches = check_plagiarism("Some abstract", threshold=0.75)
```

---

## ğŸ§  Models & Training

You can retrain the classifier using:

```bash
python train/train_domain_classifier.py
```

You can also generate corpus embeddings for plagiarism detection using:

```bash
python train/build_embeddings.py
```

Ensure you have `corpus_texts.pkl` with text entries in your corpus before building.

---

## ğŸ§© Technologies Used

| Technology        | Purpose                     |
|-------------------|-----------------------------|
| Python ğŸ         | Core Programming Language   |
| Streamlit ğŸ”´       | Web UI Framework            |
| scikit-learn âš™ï¸    | ML model building           |
| SentenceTransformers ğŸ§  | Semantic embeddings       |
| HuggingFace ğŸ¤—     | Text Summarization Model    |
| NumPy ğŸ“          | Vector calculations         |

---

## ğŸ“‚ Sample Data Format

For domain classification, training data is in format:

```python
X = ["Paper abstract 1", "Paper abstract 2", ...]
y = ["AI", "Physics", ...]
```

For plagiarism:

- Save texts and their embeddings into a `dict` and use `joblib.dump(...)` to `corpus_embeddings.pkl`.

---

## ğŸ’¡ Future Enhancements

- âœï¸ Support for **multiple file upload**
- ğŸ§¬ Add **semantic topic modeling**
- ğŸ“ˆ Add analytics dashboard (plots/graphs)
- ğŸ” Add user authentication & cloud support

---

## â“ FAQ

### 1. Can I upload a `.docx` file?
No, currently only `.pdf` files are supported.

### 2. How is plagiarism checked?
We use **cosine similarity** on SBERT sentence embeddings.

### 3. How do I add more domains?
Add new labeled data in `train/train_domain_classifier.py` and retrain.

---

## ğŸ§‘â€ğŸ’» Contributors

- **Amal Prasad Trivedi** â€“ Developer, ML Engineer  
  [![LinkedIn](https://img.shields.io/badge/LinkedIn-blue?logo=linkedin)](https://www.linkedin.com/in/amal-prasad-trivedi-b47718271/)  
  [![GitHub](https://img.shields.io/badge/GitHub-black?logo=github)](https://github.com/amalprasadtrivedi)

---

## ğŸ“„ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

---

## ğŸ™Œ Acknowledgements

- ğŸ¤— HuggingFace for their NLP models
- ğŸ§  SBERT team for semantic sentence embeddings
- ğŸ¯ Streamlit for providing an easy-to-use UI framework

---

## ğŸ—‚ï¸ Resources & References

- [SBERT Documentation](https://www.sbert.net/)
- [Streamlit Documentation](https://docs.streamlit.io/)
- [Scikit-Learn Docs](https://scikit-learn.org/)
- [RAKE Algorithm](https://pypi.org/project/rake-nltk/)

---

**Made with â¤ï¸ for researchers and students by Amal Prasad Trivedi.**
